{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training an Open Book Model for Q & A","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os \nos.environ['CUDA_VISIBLE_DEVICES'] = \"0.1\"\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer, EarlyStoppingCallback, AutoModelForMultipleChoice, TrainingmArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n\nVER = 2\n# Train with subset of 60K\nNUM_TRAIN_SAMPLES = 1_024\n# Parameter efficient fine tuning \n\nUSE_PEFT = False\n\nFREEZE_LAYERS = 18\n\nFREEZE_EMBEDDINGS = True\n\nMAX_INPUT = 256\n\nMODEL = 'microsoft/deberta-v3-large'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid = pd.read_csv(\"/kaggle/input/60k-data-with-context-v2/train_with_context2.csv\")\nprint(\"df shape\", df_valid.shape)\n\ndf_valid.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv\")\n#df_train = df_train.drop(columns=\"source\")\n#df_train = df_train.fllna(\"\").sample(NUM_TRAIN_SAMPLES)\nprint(\"Train data size: \", df_train.shape)\ndf_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.item()}\n\ndef preprocess(example):\n    first_sentence = ['[CLS]' + example['context'] ] * 5\n    second_sentences = [\" ####\" + example['prompt'] + \" [SEP]\" + example[option] + \" [SEP]\" for option in \"ABCDE\"]\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation = \"only_first\", max_length=MAX_INPUT,\n                                 add_special_tokens = False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k,v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        batch = {k:v.view(batch_size, num_choices, -1) for k,v in batch.items()}","metadata":{},"execution_count":null,"outputs":[]}]}