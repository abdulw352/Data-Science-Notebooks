{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training an Open Book Model for Q & A","metadata":{}},{"cell_type":"markdown","source":"For training a model for use with Open Book Q&A need a csv that contains: `prompt` (\"questions\"), `A,B,C,D,E` (answer choices), and also a column with the `context`.","metadata":{}},{"cell_type":"code","source":"import os \nos.environ['CUDA_VISIBLE_DEVICES'] = \"0.1\"\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer, EarlyStoppingCallback, AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n\nVER = 2\n# Train with subset of 60K\nNUM_TRAIN_SAMPLES = 1_024\n# Parameter efficient fine tuning \n\nUSE_PEFT = False\n\nFREEZE_LAYERS = 18\n\nFREEZE_EMBEDDINGS = True\n\nMAX_INPUT = 256\n\nMODEL = 'microsoft/deberta-v3-large'","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:33:09.494812Z","iopub.execute_input":"2023-10-24T02:33:09.495850Z","iopub.status.idle":"2023-10-24T02:33:09.503498Z","shell.execute_reply.started":"2023-10-24T02:33:09.495808Z","shell.execute_reply":"2023-10-24T02:33:09.502570Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_valid = pd.read_csv(\"/kaggle/input/60k-data-with-context-v2/train_with_context2.csv\")\nprint(\"df shape\", df_valid.shape)\n\ndf_valid.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:33:12.272510Z","iopub.execute_input":"2023-10-24T02:33:12.272879Z","iopub.status.idle":"2023-10-24T02:33:12.352865Z","shell.execute_reply.started":"2023-10-24T02:33:12.272849Z","shell.execute_reply":"2023-10-24T02:33:12.351753Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"df shape (200, 8)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Which of the following statements accurately d...   \n1  Which of the following is an accurate definiti...   \n2  Which of the following statements accurately d...   \n3  What is the significance of regularization in ...   \n4  Which of the following statements accurately d...   \n\n                                             context  \\\n0  The presence of a clustered thick disk-like co...   \n1  Many of these systems evolve in a self-similar...   \n2  It is possible that this usage is related with...   \n3  Renormalization is distinct from regularizatio...   \n4  Several qualitative observations can be made o...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>context</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The presence of a clustered thick disk-like co...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Many of these systems evolve in a self-similar...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>It is possible that this usage is related with...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Renormalization is distinct from regularizatio...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>Several qualitative observations can be made o...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv\")\ndf_train = df_train.drop(columns=\"source\")\ndf_train = df_train.fllna(\"\").sample(NUM_TRAIN_SAMPLES)\nprint(\"Train data size: \", df_train.shape)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:33:12.875960Z","iopub.execute_input":"2023-10-24T02:33:12.876367Z","iopub.status.idle":"2023-10-24T02:33:21.603725Z","shell.execute_reply.started":"2023-10-24T02:33:12.876332Z","shell.execute_reply":"2023-10-24T02:33:21.602764Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Train data size:  (60347, 9)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  In relation to Eunice Fay McKenzie's career, w...   \n1  How does Modified Newtonian Dynamics (MOND) im...   \n2  Which of the following statements accurately d...   \n3  What is the significance of the Museum of the ...   \n4  What was the previous name of the Christian Sc...   \n\n                                             context  \\\n0  Eunice Fay McKenzie (February 19, 1918 â€“ April...   \n1  The presence of a clustered thick disk-like co...   \n2  Woody Hartman is a retired American soccer goa...   \n3  The Museum of the Occupation of Latvia () is a...   \n4  It was named the Evangelical School for the De...   \n\n                                                   A  \\\n0  McKenzie showcased her singing talents in nume...   \n1  MOND is a theory that increases the discrepanc...   \n2  Ray Montgomerie is a former footballer who pla...   \n3  The Museum of the Occupation of Latvia is a me...   \n4            The Christian School for the Deaf (CSD)   \n\n                                                   B  \\\n0  McKenzie is primarily remembered for her starr...   \n1  MOND explains the missing baryonic mass in gal...   \n2  Ray Montgomerie is a former footballer who pla...   \n3  The Museum of the Occupation of Latvia showcas...   \n4           The Christian School for the Blind (CSB)   \n\n                                                   C  \\\n0  McKenzie gained recognition for her role as a ...   \n1  MOND is a theory that reduces the observed mis...   \n2  Ray Montgomerie is a former footballer who pla...   \n3  The Museum of the Occupation of Latvia was est...   \n4  The Evangelical School and Chapel for the Deaf...   \n\n                                                   D  \\\n0  McKenzie's collaborations with director Blake ...   \n1  MOND is a theory that eliminates the observed ...   \n2  Ray Montgomerie is a former footballer who pla...   \n3  The Museum of the Occupation of Latvia primari...   \n4          The Evangelical School for the Deaf (ESD)   \n\n                                                   E answer  source  \n0  McKenzie's successful career in sound films co...      B       1  \n1  MOND's impact on the observed missing baryonic...      E       1  \n2  Ray Montgomerie is a former footballer who pla...      B       1  \n3  The Museum of the Occupation of Latvia is a mu...      C       1  \n4         The Evangelical School for the Blind (ESB)      D       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>context</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In relation to Eunice Fay McKenzie's career, w...</td>\n      <td>Eunice Fay McKenzie (February 19, 1918 â€“ April...</td>\n      <td>McKenzie showcased her singing talents in nume...</td>\n      <td>McKenzie is primarily remembered for her starr...</td>\n      <td>McKenzie gained recognition for her role as a ...</td>\n      <td>McKenzie's collaborations with director Blake ...</td>\n      <td>McKenzie's successful career in sound films co...</td>\n      <td>B</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How does Modified Newtonian Dynamics (MOND) im...</td>\n      <td>The presence of a clustered thick disk-like co...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND explains the missing baryonic mass in gal...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>MOND's impact on the observed missing baryonic...</td>\n      <td>E</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>Woody Hartman is a retired American soccer goa...</td>\n      <td>Ray Montgomerie is a former footballer who pla...</td>\n      <td>Ray Montgomerie is a former footballer who pla...</td>\n      <td>Ray Montgomerie is a former footballer who pla...</td>\n      <td>Ray Montgomerie is a former footballer who pla...</td>\n      <td>Ray Montgomerie is a former footballer who pla...</td>\n      <td>B</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of the Museum of the ...</td>\n      <td>The Museum of the Occupation of Latvia () is a...</td>\n      <td>The Museum of the Occupation of Latvia is a me...</td>\n      <td>The Museum of the Occupation of Latvia showcas...</td>\n      <td>The Museum of the Occupation of Latvia was est...</td>\n      <td>The Museum of the Occupation of Latvia primari...</td>\n      <td>The Museum of the Occupation of Latvia is a mu...</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What was the previous name of the Christian Sc...</td>\n      <td>It was named the Evangelical School for the De...</td>\n      <td>The Christian School for the Deaf (CSD)</td>\n      <td>The Christian School for the Blind (CSB)</td>\n      <td>The Evangelical School and Chapel for the Deaf...</td>\n      <td>The Evangelical School for the Deaf (ESD)</td>\n      <td>The Evangelical School for the Blind (ESB)</td>\n      <td>D</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = ['[CLS]' + example['context'] ] * 5\n    second_sentences = [\" ####\" + example['prompt'] + \" [SEP] \" + example[option] if example[option] else ' ' + \" [SEP]\" for option in \"ABCDE\"]\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation = \"only_first\", max_length=MAX_INPUT,\n                                 add_special_tokens = False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k,v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding = self.padding,\n            max_length = self.max_length,\n            pad_to_multiple_of = self.pad_to_multiple_of,\n            return_tensors = 'pt',\n        )\n        batch = {k:v.view(batch_size, num_choices, -1) for k,v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:07:14.060312Z","iopub.execute_input":"2023-10-24T03:07:14.060823Z","iopub.status.idle":"2023-10-24T03:07:14.074389Z","shell.execute_reply.started":"2023-10-24T03:07:14.060784Z","shell.execute_reply":"2023-10-24T03:07:14.073351Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL)\ndataset_valid = Dataset.from_pandas(df_valid)\ndataset = Dataset.from_pandas(df_train)\n#dataset = dataset.remove_columns(['__index_level_0__'])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:34:19.423023Z","iopub.execute_input":"2023-10-24T02:34:19.423414Z","iopub.status.idle":"2023-10-24T02:34:21.560518Z","shell.execute_reply.started":"2023-10-24T02:34:19.423384Z","shell.execute_reply":"2023-10-24T02:34:21.559563Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer', 'source'],\n    num_rows: 60347\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt','context','A','B','C','D','E', 'answer'])\ntokenized_dataset = dataset.map(preprocess, remove_columns=['prompt','context','A','B','C','D','E','answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:43:47.487777Z","iopub.execute_input":"2023-10-24T02:43:47.488638Z","iopub.status.idle":"2023-10-24T03:03:06.449239Z","shell.execute_reply.started":"2023-10-24T02:43:47.488609Z","shell.execute_reply":"2023-10-24T03:03:06.448270Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05d6e39910646f986628b79a83d1299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/60347 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3cde5eb8f24b38b14b53a75c0bbeb3"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['source', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 60347\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Build Model\n\nusing Hugging Face AutoModelForMultipleChoice. \noptionally can also use PEFT to accelerate training and uses less memory. However it has noticed that validation accuracy is lower. \nCan also feeze layers to accelerate training and lower memory use but this can also result in worse validation accuracy. ","metadata":{}},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:39:04.054264Z","iopub.execute_input":"2023-10-24T02:39:04.054667Z","iopub.status.idle":"2023-10-24T02:39:13.915678Z","shell.execute_reply.started":"2023-10-24T02:39:04.054638Z","shell.execute_reply":"2023-10-24T02:39:13.914891Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a461bd68d3ec444a9083dba7054af87a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"if FREEZE_EMBEDDINGS:\n    print('Freezing Embeddings --------------------------------------------')\n    for param in model.deberta.embeddings.parameters():\n        param.requires_grad = False\nif FREEZE_LAYERS > 0:\n    print(f\"Freezing {FREEZE_LAYERS} layers. ---------------------------------------\")\n    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n        for param in layer.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:39:13.917351Z","iopub.execute_input":"2023-10-24T02:39:13.917661Z","iopub.status.idle":"2023-10-24T02:39:13.925455Z","shell.execute_reply.started":"2023-10-24T02:39:13.917626Z","shell.execute_reply":"2023-10-24T02:39:13.924459Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Freezing Embeddings --------------------------------\nFreezing 18 layers. ---------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MAP@3 Metric ","metadata":{}},{"cell_type":"code","source":"def map_at_3(predictions, labels):\n    map_sum = 0\n    pred = np.argsort(-1*np.array(predictions), axis = 1)[:,:3]\n    for x,y in zip(pred,labels):\n        z = [1/i if y == j else 0 for i,j in zip([1,2,3],x)]\n        map_sum += np.sum(z)\n    return map_sum / len(predictions)\n\ndef compute_metrics(p):\n    predictions = p.predictions.tolist()\n    labels = p.label_ids.tolist()\n    return {\"map@3\" : map_at_3(predictions, labels)}","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:09:32.096915Z","iopub.execute_input":"2023-10-24T03:09:32.097664Z","iopub.status.idle":"2023-10-24T03:09:32.104340Z","shell.execute_reply.started":"2023-10-24T03:09:32.097626Z","shell.execute_reply":"2023-10-24T03:09:32.103470Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Train and Save\n\nTricks to train model more efficiently when low RAM\n\n- use fp16 (speeds up T4 not p100)\n- use `gradient_accumulation_steps` (this simulates large batch sizes)\n- use `gradient_checkpointing` (this uses disk to save RAM)\n- freeze model embeddings (this reduces weights to train)\n- freeze some model layers (this reduces weights to train)\n- use PEFT (reduce weights to train)\n- increase LR and decrease epochs (this reduces work)\n- use smaller model (this reduces weights to train)","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    warmup_ratio = 0.1, \n    learning_rate = 2e-5,\n    per_device_train_batch_size = 1,\n    per_device_eval_batch_size = 2,\n    num_train_epochs = 2,\n    report_to = 'none',\n    output_dir = f'./checkpoints_{VER}',\n    overwrite_output_dir = True,\n    fp16 = True,\n    gradient_accumulation_steps = 8,\n    logging_steps = 25,\n    evaluation_strategy = 'steps',\n    eval_steps = 25,\n    save_strategy = 'steps',\n    save_steps = 25,\n    load_best_model_at_end = False,\n    metric_for_best_model = 'map@3',\n    lr_scheduler_type = 'cosine',\n    weight_decay = 0.01,\n    save_total_limit = 2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:39:35.146327Z","iopub.execute_input":"2023-10-24T02:39:35.146692Z","iopub.status.idle":"2023-10-24T02:39:35.212587Z","shell.execute_reply.started":"2023-10-24T02:39:35.146665Z","shell.execute_reply":"2023-10-24T02:39:35.211635Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    tokenizer = tokenizer,\n    data_collator = DataCollatorForMultipleChoice(tokenizer = tokenizer),\n    train_dataset = tokenized_dataset,\n    eval_dataset = tokenized_dataset_valid,\n    compute_metrics = compute_metrics,\n)\n\ntrainer.train()\ntrainer.save_model(f'model_v{VER}')","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:09:34.328894Z","iopub.execute_input":"2023-10-24T03:09:34.329306Z","iopub.status.idle":"2023-10-24T03:35:23.071856Z","shell.execute_reply.started":"2023-10-24T03:09:34.329272Z","shell.execute_reply":"2023-10-24T03:35:23.070512Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='426' max='15086' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  426/15086 25:21 < 14:36:31, 0.28 it/s, Epoch 0.06/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Map@3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.604000</td>\n      <td>1.609468</td>\n      <td>0.354167</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.625000</td>\n      <td>1.609424</td>\n      <td>0.354167</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.619000</td>\n      <td>1.609385</td>\n      <td>0.395833</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.626800</td>\n      <td>1.609214</td>\n      <td>0.439167</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.611400</td>\n      <td>1.609014</td>\n      <td>0.493333</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.614300</td>\n      <td>1.608638</td>\n      <td>0.551667</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.617300</td>\n      <td>1.608003</td>\n      <td>0.615000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.619200</td>\n      <td>1.606157</td>\n      <td>0.687500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.605600</td>\n      <td>1.601934</td>\n      <td>0.731667</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.596000</td>\n      <td>1.577207</td>\n      <td>0.769167</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>1.520100</td>\n      <td>1.427263</td>\n      <td>0.800833</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.293500</td>\n      <td>1.249993</td>\n      <td>0.781667</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>1.143000</td>\n      <td>1.188693</td>\n      <td>0.748333</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.176000</td>\n      <td>1.095551</td>\n      <td>0.818333</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>1.123100</td>\n      <td>1.048957</td>\n      <td>0.815000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.951900</td>\n      <td>1.005614</td>\n      <td>0.807500</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.956200</td>\n      <td>0.891788</td>\n      <td>0.820833</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m      3\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     compute_metrics \u001b[38;5;241m=\u001b[39m compute_metrics,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1927\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1927\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2265\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2265\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2322\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2320\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2321\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2322\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled:\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m     \u001b[38;5;66;03m# config `stage3_gather_16bit_weights_on_model_save` is True\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2803\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2803\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2861\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2859\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1988\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1986\u001b[0m         safe_save_file(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1988\u001b[0m         \u001b[43msave_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1991\u001b[0m     path_to_weights \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, _add_variant(WEIGHTS_NAME, variant))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"trainer.save_model(f\"model_v{VER}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:36:21.275416Z","iopub.execute_input":"2023-10-24T03:36:21.276093Z","iopub.status.idle":"2023-10-24T03:36:23.952540Z","shell.execute_reply.started":"2023-10-24T03:36:21.276059Z","shell.execute_reply":"2023-10-24T03:36:23.951698Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Verifying saved Model\n\nChecking to see if the model saved correctly","metadata":{}},{"cell_type":"code","source":"load_model = AutoModelForMultipleChoice.from_pretrained(f'model_v{VER}')\ntrainer = Trainer(model = load_model)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:36:26.264626Z","iopub.execute_input":"2023-10-24T03:36:26.265008Z","iopub.status.idle":"2023-10-24T03:36:32.021070Z","shell.execute_reply.started":"2023-10-24T03:36:26.264978Z","shell.execute_reply":"2023-10-24T03:36:32.019942Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/60k-data-with-context-v2/train_with_context2.csv\")\ntokenized_test_dataset = Dataset.from_pandas(test_df).map(\npreprocess, remove_columns = ['prompt','context','A','B','C','D','E'])\n\ntest_predictions = trainer.predict(tokenized_test_dataset).predictions\npredictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_string = test_df['prediction'] = [' '.join(row) for row in predictions_as_answer_letters[:,:3]]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:36:35.240922Z","iopub.execute_input":"2023-10-24T03:36:35.241702Z","iopub.status.idle":"2023-10-24T03:36:59.560094Z","shell.execute_reply.started":"2023-10-24T03:36:35.241667Z","shell.execute_reply":"2023-10-24T03:36:59.559152Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd01add2a4994ef9a02e607bbdea4782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"### Compute Validation Score","metadata":{}},{"cell_type":"code","source":"def precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u].split()\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:37:34.313896Z","iopub.execute_input":"2023-10-24T03:37:34.314581Z","iopub.status.idle":"2023-10-24T03:37:34.321678Z","shell.execute_reply.started":"2023-10-24T03:37:34.314547Z","shell.execute_reply":"2023-10-24T03:37:34.320704Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"m = MAP_at_3(test_df.prediction.values, test_df.answer.values)\nprint(\"CV MAP@3 = \", m)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:37:34.840634Z","iopub.execute_input":"2023-10-24T03:37:34.841460Z","iopub.status.idle":"2023-10-24T03:37:34.848187Z","shell.execute_reply.started":"2023-10-24T03:37:34.841426Z","shell.execute_reply":"2023-10-24T03:37:34.847110Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"CV MAP@3 =  0.8208333333333334\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}