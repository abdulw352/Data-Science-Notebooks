{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":6640818,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n\nfrom IPython.display import display_html, clear_output, Markdown\nfrom gc import collect\nimport copy, pandas as pd, numpy as np, joblib, ctypes\nfrom os import system, getpid, walk\nfrom psutil import Process\nfrom copy import deepcopy\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nfrom tqdm.notebook import tqdm\nfrom pprint import pprint \nfrom colorama import Fore, Style, init\n\nimport lightgbm\nfrom itertools import combinations \nfrom sklearn.model_selection import KFold\n\ncollect()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:13:51.399953Z","iopub.execute_input":"2023-11-10T04:13:51.400585Z","iopub.status.idle":"2023-11-10T04:13:51.539547Z","shell.execute_reply.started":"2023-11-10T04:13:51.400556Z","shell.execute_reply":"2023-11-10T04:13:51.538449Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"CPU times: user 130 ms, sys: 1.03 ms, total: 131 ms\nWall time: 130 ms\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"3076"},"metadata":{}}]},{"cell_type":"code","source":"%%time \n\nfrom sklearn.model_selection import (RepeatedStratifiedKFold as RSKF,\n                                    StratifiedKFold as SKF,\n                                    KFold,\n                                    RepeatedKFold as RKF,\n                                    cross_val_score)\nfrom lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\nfrom xgboost import XGBRegressor as XGBR\nfrom catboost import CatBoostRegressor as CBR\nfrom sklearn.ensemble import HistGradientBoostingRegressor as HGBR\nfrom sklearn.metrics import mean_absolute_error as mae, make_scorer\n\ncollect()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:13:51.541581Z","iopub.execute_input":"2023-11-10T04:13:51.541951Z","iopub.status.idle":"2023-11-10T04:13:51.665673Z","shell.execute_reply.started":"2023-11-10T04:13:51.541919Z","shell.execute_reply":"2023-11-10T04:13:51.664743Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"CPU times: user 111 ms, sys: 41 µs, total: 111 ms\nWall time: 111 ms\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"%%time \n\ndef GetMemUsage():\n    \"\"\"\n    defines the memory usage across the kernel.\n    \"\"\"\n    \n    pid = getpid()\n    py = Process(pid)\n    memory_use = py.memory_info()[0] / 2. * 30\n    return f\"RAM memory GB usage = {memory_use :.4f}\"\n\nfrom sklearn import set_config\nset_config(transform_output = \"pandas\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:13:51.666906Z","iopub.execute_input":"2023-11-10T04:13:51.667263Z","iopub.status.idle":"2023-11-10T04:13:51.676639Z","shell.execute_reply.started":"2023-11-10T04:13:51.667237Z","shell.execute_reply":"2023-11-10T04:13:51.675676Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"CPU times: user 36 µs, sys: 0 ns, total: 36 µs\nWall time: 39.8 µs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Configuration Class","metadata":{}},{"cell_type":"code","source":"%%time \n\nclass CFG:\n    \"\"\"\n    Configuration class for parameters and CV strategy for tuning and trainig\n    use CAPITAL LETTERS when filling in parameters.\n    \"\"\"\n    \n    # Data preparation:\n    version_nb = 5\n    test_req = \"N\"\n    test_frac = 0.01\n    load_tr_data = \"N\"\n    gpu_switch = \"OFF\"\n    state = 42\n    target = 'target'\n    \n    path = f'/kaggle/input/optiver-memoryreduceddatasets/'\n    test_path = f'/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\n    df_choice = f'XTrIntCmpNewFtre.parquet'\n    mdl_path = f'/kaggle/working/BaselineML/'\n    inf_path = f'/kaggle/input/optiverbaselinemodels/'\n    \n    # Model Training:\n    methods = ['LGBMR', 'CBR', 'HGBR']\n    ML = \"Y\"\n    n_splits = 5\n    n_repeats = 1\n    nbrnd_erly_stp = 100\n    mdlcv_mthd = 'KF'\n    \n    # Ensemble\n    ensemble_req = \"N\"\n    enscv_mthd = \"KF\"\n    metric_obj = 'minimize'\n    ntrials = 10 if test_req == \"Y\" else 200\n    ens_weights = [0.54, 0.44, 0.02]\n    \n    # Inference:\n    inference_req = \"Y\"\n    \n    # Global variables for plotting: \n    grid_specs = {'visible' : True, 'which' : 'both', 'linestyle' : '--',\n                 'color' : 'lightgrey', 'linewidth' : 0.75}\n    title_specs = {\"fontsize\" : 9, 'fontweight' : 'bold', 'color' : 'tab:blue'}\n    \n    print(\"Configuration done!\")\n    collect()\n    print(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:30.375895Z","iopub.execute_input":"2023-11-10T04:20:30.376754Z","iopub.status.idle":"2023-11-10T04:20:30.523585Z","shell.execute_reply.started":"2023-11-10T04:20:30.376714Z","shell.execute_reply":"2023-11-10T04:20:30.522548Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Configuration done!\nRAM memory GB usage = 6466990080.0000\nCPU times: user 137 ms, sys: 122 µs, total: 137 ms\nWall time: 136 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Cross validation \n","metadata":{}},{"cell_type":"code","source":"%%time \n\nall_cv = {\"KF\" : KFold(n_splits = CFG.n_splits, shuffle = True, random_state = CFG.state),\n         'RKF' : RKF(n_splits = CFG.n_splits, n_repeats = CFG.n_repeats ,random_state = CFG.state),\n         'RSKF' : RSKF(n_splits = CFG.n_splits, n_repeats = CFG.n_repeats, random_state = CFG.state),\n         'SKF' : SKF(n_splits = CFG.n_splits, shuffle = True, random_state = CFG.state)}\n\n# Defining the metric\ndef ScoreMetric(y_true, y_pred) -> float:\n    \"\"\"\n    Calculates the metric for the competition \n    y_true = ground truth np.array\n    y_pred = predictions\n    return = metric value (float)\n    \"\"\"\n    return mae(y_true, y_pred)\n\n# Custom scorer for cross_val_predict\nmyscorer = make_scorer(ScoreMetric, greater_is_better = False, needs_proba = False)\n\ncollect()\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:33.202320Z","iopub.execute_input":"2023-11-10T04:20:33.203060Z","iopub.status.idle":"2023-11-10T04:20:33.341525Z","shell.execute_reply.started":"2023-11-10T04:20:33.203020Z","shell.execute_reply":"2023-11-10T04:20:33.340434Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"RAM memory GB usage = 6466990080.0000\nCPU times: user 129 ms, sys: 3.73 ms, total: 133 ms\nWall time: 131 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Conversion and Adjustment","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef goto_conversion(listOfOdds, total = 1, eps = 1e-6, isAmericanOdds = False):\n    \n    \"\"\"\n    Function for converting odds to probabilities\n    \n    The function first checks if the odds are in American format \n    and if so converts them to decimal odds if needed. Then computes the \n    probabilities based on the inverse of the odds. After this calculates the\n    standard error (SE) for each probability. Ends with adjusting probabilities\n    by stepping back based on the SE to ensure the sum is equal to the `total`.\n    \n    returns adjusted probabilities.\n    =====================================================\n    Parameters\n    _____________________________________________________\n    listOfOdds: list\n        a list of odds that is either in American or decimal format\n    total: float\n        total sum of probabilities\n    eps: float\n        small value to prevent division by 0\n    isAmericanOdds: bool\n        A boolean flag indicating whether the input odds are in American format\n    \n    \"\"\"\n    \n    # Converting American odds to Decimal odds \n    if isAmericanOdds:\n        for i in range(len(listOfOdds)):\n            currOdds = listOfOdds[i]\n            isNegativeAmericanOdds = currOdds < 0\n            if isNegativeAmericanOdds:\n                currDecimalOdds = 1 + (100/(currOdds*-1))\n            else:\n                # Is non-negative 'merican odds\n                currDecimalOdds = 1 + (currOdds/100)\n            listOfOdds[i] = currDecimalOdds\n        \n    # Error catchers \n    if len(listOfOdds) < 2:\n        raise ValueError('len(listOfOdds) must be >= 2')\n    if any(x < 1 for x in listOfOdds):\n        raise ValueError(\"All odds must be >= 1, set isAmericanOdds parameter to True if using American Odds.\")\n    \n    # Computation:\n    # init probabilities using inverse odds\n    listOfProbabilities = [1/x for x in listOfOdds]\n    \n    # compute the standard error (SE) for each proabilitiy\n    listOfSe = [pow((x-x**2)/x, 0.5) for x in listOfProbabilities]\n    \n    # compute how many steps for SE the probabilityies should step back by\n    step = (sum(listOfProbabilities) - total)/sum(listOfSe)\n    \n    outputListOfProbabilities = [min(max(x - (y*step), eps), 1) for x,y in zip(listOfProbabilities, listOfSe)]\n    \n    return outputListOfProbabilities\n\ndef zero_sum(listOfProces, listOfVolumes):\n    \"\"\"\n    Adjusts the list of prices and volumes to achieve a zero-sum condition.\n    -----------------------------------------------------------------------\n    Parameters\n    ----------\n    listOfPrices: list of the prices\n    listOfVolumes: list of volumes corresponding to the prices.\n    \n    =======================================================================\n    Computes Standard Error (SE) for each price based on the volumes.\n    Then adjusts the prices by scaling them using the standard errors to achieve\n    a zero-sum condition.\n    \n    returns adjusted prices\n    \n    \"\"\"\n    # compute standard errors assuming standard deviation is same for all stocks \n    listOfSe = [x**0.5 for x in listOfVolumes]\n    step = sum(listOfPrices)/sum(listofSe)\n    outputListOfPrices = [x - (y*step) for x,y in zip(listOfPrices,listOfSe)]\n    return outputListOfPrices\n\ncollect()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:33.626908Z","iopub.execute_input":"2023-11-10T04:20:33.627261Z","iopub.status.idle":"2023-11-10T04:20:33.772779Z","shell.execute_reply.started":"2023-11-10T04:20:33.627233Z","shell.execute_reply":"2023-11-10T04:20:33.771720Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"CPU times: user 130 ms, sys: 1.84 ms, total: 132 ms\nWall time: 131 ms\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load and Prepare training \n","metadata":{}},{"cell_type":"code","source":"%%time \nCFG.load_tr_data = \"Y\"\nCFG.test_req = \"Y\"\n\nif (CFG.load_tr_data == \"Y\" or CFG.ML == \"Y\") and CFG.test_req == 'Y':\n    if isinstance(CFG.test_frac, float):\n        X = pd.read_parquet(CFG.path + CFG.df_choice).sample(frac = CFG.test_frac)\n    else:\n        X = pd.read_parquet(CFG.path + CFG.df_choice).sample(n = CFG.test_frac)\n    \n    y = pd.read_parquet(CFG.path + f\"Ytrain.parquet\").loc[X.index].squeeze()\n    print(f\"Sampled train shapes for coding tests = {X.shape} {y.shape}\")\n    \n    X.index, y.index = range(len(X)), range(len(y))\n    \n    print(X.columns)\n    \nelif CFG.load_tr_data == \"Y\" or CFG.ML == \"Y\":\n    X = pd.read_parquet(CFG.path + CFG.df_choice)\n    y = pd.read_parquet(CFG.path + \"Ytrain.parquet\").squeeze()\n    \n    print(f\"Train shapes for code testing = {X.shape} {y.shape}\")\n    \nelif CFG.load_tr_data != \"Y\" or CFG.inference_req == \"Y\":\n    print(f\"Train data is not required since inferring from the model\")\n    \ncollect()\nlibc.malloc_trim(0)\n\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:34.610909Z","iopub.execute_input":"2023-11-10T04:20:34.611761Z","iopub.status.idle":"2023-11-10T04:20:44.386921Z","shell.execute_reply.started":"2023-11-10T04:20:34.611732Z","shell.execute_reply":"2023-11-10T04:20:44.386010Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Sampled train shapes for coding tests = (52379, 52) (52379,)\nIndex(['overall_medvol', 'first5min_medvol', 'last5min_medvol',\n       'seconds_in_bucket', 'imbalance_buy_sell_flag', 'imbalance_size',\n       'matched_size', 'bid_size', 'ask_size', 'reference_price', 'far_price',\n       'near_price', 'ask_price', 'bid_price', 'wap', 'imb_s1', 'imb_s2',\n       'far_price_reference_price_imb', 'near_price_reference_price_imb',\n       'near_price_far_price_imb', 'bid_price_reference_price_imb',\n       'bid_price_far_price_imb', 'bid_price_near_price_imb',\n       'ask_price_reference_price_imb', 'ask_price_far_price_imb',\n       'ask_price_near_price_imb', 'ask_price_bid_price_imb',\n       'wap_reference_price_imb', 'wap_far_price_imb', 'wap_near_price_imb',\n       'wap_bid_price_imb', 'wap_ask_price_imb',\n       'near_price_far_price_reference_price_imb2',\n       'bid_price_far_price_reference_price_imb2',\n       'bid_price_near_price_reference_price_imb2',\n       'bid_price_near_price_far_price_imb2',\n       'ask_price_far_price_reference_price_imb2',\n       'ask_price_near_price_reference_price_imb2',\n       'ask_price_near_price_far_price_imb2',\n       'ask_price_bid_price_reference_price_imb2',\n       'ask_price_bid_price_far_price_imb2',\n       'ask_price_bid_price_near_price_imb2',\n       'wap_far_price_reference_price_imb2',\n       'wap_near_price_reference_price_imb2', 'wap_near_price_far_price_imb2',\n       'wap_bid_price_reference_price_imb2', 'wap_bid_price_far_price_imb2',\n       'wap_bid_price_near_price_imb2', 'wap_ask_price_reference_price_imb2',\n       'wap_ask_price_far_price_imb2', 'wap_ask_price_near_price_imb2',\n       'wap_ask_price_bid_price_imb2'],\n      dtype='object')\nRAM memory GB usage = 8970854400.0000\nCPU times: user 4.96 s, sys: 3.6 s, total: 8.56 s\nWall time: 9.77 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Initialize model configurations","metadata":{}},{"cell_type":"code","source":"%%time \n\n# Initializing Models \n\nif CFG.ML == \"Y\":\n    Mdl_Master = \\\n    {\n        \"CBR\" : CBR(**{'task_type' : \"GPU\" if CFG.gpu_switch == \"ON\" else \"CPU\",\n                      'objective' : \"MAE\",\n                      'eval_metric' : 'MAE',\n                      'bagging_temperature' : 0.5,\n                      'colsample_bylevel' : 0.7,\n                      'iterations' : 500,\n                      'learning_rate' : 0.065,\n                      'od_wait' : 25,\n                      'max_depth' : 7,\n                       'l2_leaf_reg' : 1.5,\n                       'min_data_in_leaf' : 1000,\n                       'random_strength' : 0.65,\n                       'verbose' : 0,\n                       'use_best_model' : True,\n                      }),\n        'LGBMR' : LGBMR(**{'device' : 'gpu' if CFG.gpu_switch == \"ON\" else \"cpu\",\n                           'objective' : 'regression_l1',\n                           'boosting_type' : 'gbdt',\n                           'random_state' : CFG.state,\n                           'colsample_bytree' : 0.7,\n                           'subsample' : 0.65,\n                           'learning_rate' : 0.065,\n                           'max_depth' : 6,\n                           'n_estimators' : 500,\n                           'num_leaves' : 150,\n                           'reg_alpha' : 0.01,\n                           'reg_lambda' : 3.25,\n                           'verbose' : -1,\n            \n                        }),\n        'XGBR' : XGBR(**{'tree_method' : 'gpu_hist' if CFG.gpu_switch == 'ON' else 'hist',\n                         'objective' : 'reg:absoluteerror',\n                         'random_state' : CFG.state,\n                         'colsample_bytree' : 0.7,\n                         'learning_rate' : 0.07,\n                         'max_depth' : 6,\n                         'n_estimators' : 500,\n                         'reg_alpha' : 0.025,\n                         'reg_lambda' : 1.75,\n                         'min_child_weight' : 1000,\n                         'early_stopping_rounds' : CFG.nbrnd_erly_stp\n                        }),\n        \"HGBR\" : HGBR( loss = 'squared_error',\n                     learning_rate = 0.075,\n                     early_stopping = True,\n                     max_iter = 200,\n                     max_depth = 6,\n                     min_samples_leaf = 1500,\n                     l2_regularization = 1.75,\n                     scoring = myscorer,\n                     random_state = CFG.state)\n    }\n    \ncollect()\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:44.389001Z","iopub.execute_input":"2023-11-10T04:20:44.389571Z","iopub.status.idle":"2023-11-10T04:20:44.510890Z","shell.execute_reply.started":"2023-11-10T04:20:44.389535Z","shell.execute_reply":"2023-11-10T04:20:44.510007Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"RAM memory GB usage = 8970854400.0000\nCPU times: user 110 ms, sys: 2.08 ms, total: 113 ms\nWall time: 111 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n    # Initialize the models from configuration class:\n    methods = CFG.methods\n    \n    # Initialize a folder to store the trained and fitted models\n    system('mkdir BaselineML')\n    \n    # Init the model path for storage \n    model_path = CFG.mdl_path\n    \n    # Initializing the CV object:\n    cv = all_cv[CFG.mdlcv_mthd]\n    \n    # Initializing score dataframe \n    Scores = pd.DataFrame(index = range(CFG.n_splits * CFG.n_repeats),\n                         columns = methods).fillna(0).astype(np.float32)\n    \n    FtreImp = pd.DataFrame(index = X.columns, columns = [methods]).fillna(0)\n    \ncollect()\nlibc.malloc_trim(0)\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:20:44.512029Z","iopub.execute_input":"2023-11-10T04:20:44.512325Z","iopub.status.idle":"2023-11-10T04:20:44.646790Z","shell.execute_reply.started":"2023-11-10T04:20:44.512292Z","shell.execute_reply":"2023-11-10T04:20:44.645920Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"RAM memory GB usage = 8152412160.0000\nCPU times: user 121 ms, sys: 6.17 ms, total: 127 ms\nWall time: 125 ms\n","output_type":"stream"},{"name":"stderr","text":"mkdir: cannot create directory ‘BaselineML’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"if CFG.ML == \"Y\":\n    print(\"=\"*25, \"Trainig\", \"-\" * 25)\n    \n    # Initializing CV splitting \n    for fold_nb, (train_idx, val_idx) in tqdm(enumerate(cv.split(X,y)),\n                                             f\"{CFG.mdlcv_mthd} CV {CFG.n_splits} * {CFG.n_repeats}\"):\n        # creating the CV folds\n        X_train = X.iloc[train_idx]\n        X_val = X.iloc[val_idx]\n        y_train = y.iloc[train_idx]\n        y_val = y.iloc[val_idx]\n        \n        print(f\"-------------- Fold {fold_nb} ------------------\")\n        \n        # Fitting the models \n        for method in methods:\n            model = Mdl_Master[method]\n            if method == \"LGBMR\":\n                model.fit(X_train, y_train,\n                         eval_set = [(X_val, y_val)],\n                         verbose = 0,\n                         eval_metric = 'mae',\n                         callbacks = [log_evaluation(0,),\n                                     early_stopping(CFG.nbrnd_erly_stp, verbose = False)])\n            elif method == \"XGBR\":\n                model.fit(X_train, y_train,\n                         eval_set = [(X_val,y_val)],\n                         verbose = 0,\n                         eval_metric = 'mae')\n            elif method == \"CBR\":\n                model.fit(X_train, y_train,\n                         eval_set = [(X_val, y_val)],\n                         verbose = 0,\n                         early_stopping_rounds = CFG.nbrnd_erly_stp)\n            else:\n                model.fit(X_train, y_train)\n                \n            joblib.dump(model, CFG.mdl_path + f\"{method}v{CFG.version_nb}Fold{fold_nb}.model\")\n            \n            # Creating OOF scores\n            score = ScoreMetric(y_val, model.predict(X_val))\n            Scores.at[fold_nb, method] = score\n            num_space = 6 - len(method)\n            print(f\"----- {method} {' ' * num_space} OOF = {score:.5f} --------\")\n            \n            del num_space, score\n            \n            # Collecting Feature importance \n            try: \n                FtreImp[method] = FtreImp[method].values + (model.feature_importances_ / (CFG.n_splits * CFG.n_repeats))\n            except:\n                pass\n            \n            collect()\n            \n        del X_train, y_train, X_val, y_val\n        collect()\n            \n    clear_output()\n    print(\" Mean OOF Scores across methods\")\n    display(Scores.mean())\n    \n    try: FtreImp.to_csv(CFG.mdl_path + f\"FtreImp_V{CFG.version_nb}.csv\")\n    except: pass\n    \ncollect()\nlibc.malloc_trim(0)\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:26:01.020606Z","iopub.execute_input":"2023-11-10T04:26:01.021309Z","iopub.status.idle":"2023-11-10T04:26:43.214116Z","shell.execute_reply.started":"2023-11-10T04:26:01.021278Z","shell.execute_reply":"2023-11-10T04:26:43.213168Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":" Mean OOF Scores across methods\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"LGBMR    6.299338\nCBR      6.299090\nHGBR     6.309513\ndtype: float64"},"metadata":{}},{"name":"stdout","text":"RAM memory GB usage = 8201195520.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time \n\ndef MakeFeature(df: pd.DataFrame, prices: list) -> pd.DataFrame:\n    \"\"\"\n    The function creates new features using the prices columns. \n    \n    ------------------------------------------------------------\n    Parameters\n    ----------\n    df: pd.DataFrame\n    prices: prices columns for transformation\n    \n    -----------------------------------------------------------\n    Returns\n    --------\n    df: pd.DataFrame\n        DataFrame with addtional columns after feature engineering\n    \"\"\"\n    \n    features = ['overall_medvol', \"first5min_medvol\", \"last5min_medvol\",\n                'seconds_in_bucket', 'imbalance_buy_sell_flag',\n                'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n                'imb_s1', 'imb_s2']\n    df['imb_s1'] = df.eval('(bid_size - ask_size) / (bid_size + ask_size)').astype(np.float32)\n    df['imb_s2'] = df.eval('(imbalance_size - matched_size) / (matched_size + imbalance_sizes)').astype(np.float32)\n    \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            if i > j:\n                df[f'{a}_{b}_imb'] = df.eval(f\"({a} - {b}) / ({a} + {b})\")\n                features.append(f'{a}_{b}_imb')\n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            for k,c in enumerate(prices):\n                 if i>j and j>k:\n                    max_ = df[[a,b,c]].max(axis=1);\n                    min_ = df[[a,b,c]].min(axis=1);\n                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n\n                    df[f'{a}_{b}_{c}_imb2'] = ((max_-mid_)/(mid_-min_)).astype(np.float32);\n                    features.append(f'{a}_{b}_{c}_imb2')\n    \n    return df[features]\n\ncollect()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:26:51.455571Z","iopub.execute_input":"2023-11-10T04:26:51.455970Z","iopub.status.idle":"2023-11-10T04:26:51.628783Z","shell.execute_reply.started":"2023-11-10T04:26:51.455938Z","shell.execute_reply":"2023-11-10T04:26:51.627768Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"CPU times: user 160 ms, sys: 194 µs, total: 160 ms\nWall time: 159 ms\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"%%time \n\n# Creating the test envir\n\nCFG.inference_req = \"Y\"\nCFG.ML = \"N\"\n\nif CFG.inference_req == \"Y\":\n    try:\n        del X,y\n    except:\n        pass\n    \n    prices = ['reference_price', 'far_price','near_price',\n             'bid_price','ask_price','wap']\n    \n    # Making the test envir for inference\n    \n    import optiver2023\n    try:\n        env = optiver2023.make_env()\n        iter_test = env.iter_test()\n        print(\"Curating the ingerence environment\")\n    except:\n        pass\n    \n    # collating list of models \n    \n    models = []\n    \n    # loading the models for inference \n    \n    if CFG.ML != \"Y\":\n        model_path = CFG.inf_path\n        print(f\"Loading models from the input data for the kernel -V{CFG.version_nb}\")\n    elif CFG.ML == \"Y\":\n        model_path = CFG.mdl_path\n        print(\"Loading models from the working directory for the kernel\")\n        \n    model_label = []\n    for _, _, filename in walk(model_path):\n        model_label.extend(filename)\n    \n    models = []\n    for filename in model_label:\n        models.append(joblib.load(model_path+f\"{filename}\"))\n        \n    model_label = [m.replace(r\".model\",\"\") for m in model_label]\n    \n    model_dict = {l:m for l,m in zip(model_label, models)}\n    print(\"Trained Models\")\n    print(np.array(model_label))\n\ncollect()\nlibc.malloc_trim(0)\nprint(GetMemUsage())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T04:27:52.870239Z","iopub.execute_input":"2023-11-10T04:27:52.870605Z","iopub.status.idle":"2023-11-10T04:27:53.046962Z","shell.execute_reply.started":"2023-11-10T04:27:52.870575Z","shell.execute_reply":"2023-11-10T04:27:53.046126Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Loading models from the input data for the kernel -V5\nTrained Models\n[]\nRAM memory GB usage = 7965020160.0000\nCPU times: user 165 ms, sys: 4.93 ms, total: 170 ms\nWall time: 168 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}